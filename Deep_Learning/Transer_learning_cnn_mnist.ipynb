{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.16"
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zV3jpWWaVzxL"
      },
      "source": [
        "# Transfer Learning Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go-Au1mYVzxN"
      },
      "source": [
        "## Transfer learning is a basic appoach of model reuse and retraining\n",
        "### A model trained on one dataset for a different domain is refined by modifying some of the last layers and trained with new dataset\n",
        "    * This saves a lot of training time as we only need to modify some of the layers and retrain only those layers\n",
        "    * Also sometimes we don't have a very big dataset which we can use for training a model so we take pretrained model and retrain it by making only some of the layers trainable\n",
        "    * This is one of the basic techniques for domain adaptation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZMuPsLeVzxP"
      },
      "source": [
        "### This is a basic example from keras examples directory\n",
        "(Available @ https://github.com/keras-team/keras/blob/master/examples/mnist_transfer_cnn.py)\n",
        "\n",
        "    * - Train a simple convnet on the MNIST dataset the first 5 digits [0..4].\n",
        "    * - Freeze convolutional layers and fine-tune dense layers for the classification of digits [5..9].\n",
        "   \n",
        "\n",
        "Get to 99.8% test accuracy after 5 epochs\n",
        "for the first five digits classifier\n",
        "and 99.2% for the last five digits after transfer + fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oq-x20rjVzxQ"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import datetime\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0d0Wao5VzxV"
      },
      "source": [
        "now = datetime.datetime.now\n",
        "\n",
        "batch_size = 128  # no.of elements to be used for one iteration\n",
        "num_classes = 5   # no. of classes for training\n",
        "epochs = 5        # how many times the whole dataset should be iterated\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "# number of convolutional filters to use\n",
        "filters = 32\n",
        "# size of pooling area for max pooling\n",
        "pool_size = 2\n",
        "# convolution kernel size\n",
        "kernel_size = 3  # here kernel_size means a 3x3 filter\n",
        "\n",
        "if K.image_data_format() == 'channels_first':  # channels mean no. of color channels of the image\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    input_shape = (img_rows, img_cols, 1)    # tensorflow uses channels_last config by default"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7v5c7MuVzxZ"
      },
      "source": [
        "### Define the funtion which will run the training with input model and training data\n",
        "    This function basically does some preprocessing on training data and then runs compile and fit functions of keras.models.Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlhI0XceVzxa"
      },
      "source": [
        "def train_model(model, train, test, num_classes):\n",
        "    x_train = train[0].reshape((train[0].shape[0],) + input_shape)\n",
        "    x_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
        "    x_train = x_train.astype('float32')\n",
        "    x_test = x_test.astype('float32')\n",
        "    x_train /= 255\n",
        "    x_test /= 255\n",
        "    print('x_train shape:', x_train.shape)\n",
        "    print(x_train.shape[0], 'train samples')\n",
        "    print(x_test.shape[0], 'test samples')\n",
        "\n",
        "    # convert class vectors to binary class matrices\n",
        "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
        "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
        "\n",
        "    # compile the model\n",
        "    # you can chnage the parameters in this compile function\n",
        "    # custom funtions for loss and opitizer can be used: ref to keras documentation for more\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adadelta',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    t = now()\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              verbose=1,\n",
        "              validation_data=(x_test, y_test))\n",
        "    print('Training time: %s' % (now() - t))\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    print('Test score:', score[0])\n",
        "    print('Test accuracy:', score[1])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnJPmvcmVzxd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b20a9bf-6a22-44e0-fd08-5306cb2cc500"
      },
      "source": [
        "# Get the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C086u-fUwhNy",
        "outputId": "a55afc81-f3f1-4b7e-b9c9-e4b61e3ec88a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# create two datasets\n",
        "# one with digits below 5\n",
        "x_train_lt5 = x_train[y_train < 5]\n",
        "y_train_lt5 = y_train[y_train < 5]\n",
        "x_test_lt5 = x_test[y_test < 5]\n",
        "y_test_lt5 = y_test[y_test < 5]\n",
        "print(x_train.shape)\n",
        "print(x_train[y_train<5].shape)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(30596, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r87z5qD7wUmU"
      },
      "source": [
        "# one with digits below 5 one with 5 and above\n",
        "\n",
        "x_train_gte5 = x_train[y_train >= 5]\n",
        "y_train_gte5 = y_train[y_train >= 5] - 5\n",
        "x_test_gte5 = x_test[y_test >= 5]\n",
        "y_test_gte5 = y_test[y_test >= 5] - 5"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtmmlBX6Vzxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63f730f-1474-457f-cd28-36b18ab3032f"
      },
      "source": [
        "# define two groups of layers: feature (convolutions) and classification (dense)\n",
        "feature_layers = [\n",
        "    Conv2D(filters, kernel_size,\n",
        "           padding='valid',\n",
        "           input_shape=input_shape),\n",
        "    Activation('relu'),\n",
        "    Conv2D(filters, kernel_size),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=pool_size),\n",
        "    Dropout(0.25),\n",
        "    Flatten(),\n",
        "]\n",
        "\n",
        "classification_layers = [\n",
        "    Dense(128),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caNz-QGXVzxj"
      },
      "source": [
        "# create complete model\n",
        "model = Sequential(feature_layers + classification_layers)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LG28sPIpu-9",
        "outputId": "96f843e2-4350-485a-d6ba-9ce562c3c5d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# train model for 5-digit classification [0..4]\n",
        "train_model(model,\n",
        "            (x_train_lt5, y_train_lt5),\n",
        "            (x_test_lt5, y_test_lt5), num_classes)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (30596, 28, 28, 1)\n",
            "30596 train samples\n",
            "5139 test samples\n",
            "Epoch 1/5\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 213ms/step - accuracy: 0.2377 - loss: 1.5978 - val_accuracy: 0.3514 - val_loss: 1.5739\n",
            "Epoch 2/5\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 206ms/step - accuracy: 0.3188 - loss: 1.5737 - val_accuracy: 0.4472 - val_loss: 1.5454\n",
            "Epoch 3/5\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 214ms/step - accuracy: 0.4015 - loss: 1.5468 - val_accuracy: 0.5221 - val_loss: 1.5127\n",
            "Epoch 4/5\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 207ms/step - accuracy: 0.4554 - loss: 1.5154 - val_accuracy: 0.5877 - val_loss: 1.4741\n",
            "Epoch 5/5\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 216ms/step - accuracy: 0.5086 - loss: 1.4815 - val_accuracy: 0.6737 - val_loss: 1.4289\n",
            "Training time: 0:06:21.425220\n",
            "Test score: 1.4288829565048218\n",
            "Test accuracy: 0.6736719012260437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWRUTPmiVzxn"
      },
      "source": [
        "### Model trained in the above block can be used for classifying digits 5 to 9 by fine tuning it\n",
        "    For fine tuning we will freeze all the convolutional and maxpooling layers (feature layers)\n",
        "    This can be done by making those layers non-trainable\n",
        "    only the top(last) two layers (dense layers) are left trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQNVmjw1Vzxo"
      },
      "source": [
        "# freeze feature layers and rebuild model\n",
        "for l in feature_layers:\n",
        "    l.trainable = False\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXxNnEMIqNoA",
        "outputId": "6445f9b3-2612-45c5-a0ff-e3b3d48cde25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# transfer: train dense layers for new classification task [5..9]\n",
        "train_model(model,\n",
        "            (x_train_gte5, y_train_gte5),\n",
        "            (x_test_gte5, y_test_gte5), num_classes)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (29404, 28, 28, 1)\n",
            "29404 train samples\n",
            "4861 test samples\n",
            "Epoch 1/5\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 82ms/step - accuracy: 0.2359 - loss: 1.6055 - val_accuracy: 0.3304 - val_loss: 1.5830\n",
            "Epoch 2/5\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 78ms/step - accuracy: 0.2855 - loss: 1.5833 - val_accuracy: 0.4454 - val_loss: 1.5601\n",
            "Epoch 3/5\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 72ms/step - accuracy: 0.3348 - loss: 1.5623 - val_accuracy: 0.5521 - val_loss: 1.5377\n",
            "Epoch 4/5\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 78ms/step - accuracy: 0.3830 - loss: 1.5415 - val_accuracy: 0.6367 - val_loss: 1.5155\n",
            "Epoch 5/5\n",
            "\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 73ms/step - accuracy: 0.4411 - loss: 1.5214 - val_accuracy: 0.7015 - val_loss: 1.4934\n",
            "Training time: 0:01:40.156957\n",
            "Test score: 1.4933886528015137\n",
            "Test accuracy: 0.701501727104187\n"
          ]
        }
      ]
    }
  ]
}