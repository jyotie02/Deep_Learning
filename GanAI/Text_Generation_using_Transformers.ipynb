{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation using Transformers"
      ],
      "metadata": {
        "id": "LwGrBiVqu1Jm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing Libraries"
      ],
      "metadata": {
        "id": "ZhyUWkTcYw0p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agBmyO40C8-u"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "Zb0qcQWeY0Pr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "oYx1pSqCU1iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
      ],
      "metadata": {
        "id": "P9jGGzlnKoiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading pre-trained Model & Tokenizer"
      ],
      "metadata": {
        "id": "_iFo1iEYY3EV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained 'GPT-2' model and tokenizer\n",
        "model_name = \"gpt2-large\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "kVaHWiTtKrYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up Model & Tokenizer"
      ],
      "metadata": {
        "id": "ExTCKWcKZC1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode (no training)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "UuvajJKyKvx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting pad token\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model.generation_config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "U4SNHv9xXF-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Text"
      ],
      "metadata": {
        "id": "yPtBNsqpY_US"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zffC4oJAElsC"
      },
      "outputs": [],
      "source": [
        "# Function to generate text\n",
        "def generate_text_from_model(prompt, max_length=50, temperature=0.7):\n",
        "\n",
        "    # Encoding prompt to token\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate text\n",
        "    output = model.generate(\n",
        "        input_ids,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=temperature,\n",
        "    )\n",
        "\n",
        "    # Decode and return generated text\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text with a prompt\n",
        "def text_generation():\n",
        "\n",
        "  # Prompt input from user\n",
        "  prompt = str(input('Enter prompt: '))\n",
        "\n",
        "  # Generating text from model\n",
        "  generated_text = generate_text_from_model(prompt, max_length = 100)\n",
        "\n",
        "  # Printing generated text\n",
        "  print(generated_text)"
      ],
      "metadata": {
        "id": "K1jrVLHbzXtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_generation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWsQ8MUCatcW",
        "outputId": "ffad747e-eb22-4822-87b6-ba27cfdb0e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter prompt: i am a cricketer\n",
            "i am a cricketer, and I am not a cricket fan. I have never watched a Test match. But I know that the game is a beautiful game. It is the most beautiful sport.\n",
            "\n",
            "\"I have been to many cricket matches. And I can tell you that it is not just the players who are good. The game itself is beautiful. There is no better way to enjoy it than to watch it. So I think it's a great sport.\"\n",
            ".@c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_generation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_bp3otZbLVv",
        "outputId": "0de0a91d-1c02-43ec-e519-9e20c32c1f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter prompt: I love dogs\n",
            "I love dogs. I love my dogs, and I'm not going to let them go.\n",
            "\n",
            "\"I'm going out there to win. That's what I do. If I can't win, I'll go home and cry. But I don't want to cry.\"\n",
            ".@DerekJRivera is a dog lover. He's a fighter. And he's going after the dog that killed his dog. pic.twitter.com/QQYZj4Q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f9miafoUbm0a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}